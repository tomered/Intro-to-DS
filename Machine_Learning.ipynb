{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import sklearn \n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt      \n",
    "import math\n",
    "from collections import Counter\n",
    "%matplotlib inline                         \n",
    "from sklearn import preprocessing, linear_model, model_selection,tree\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.metrics import confusion_matrix , accuracy_score , f1_score, classification_report, make_scorer\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from IPython.display import Image, display  \n",
    "import pydotplus \n",
    "from scipy import misc\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv(file_name):\n",
    "    df=pd.read_csv(file_name)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_raiting_base_on_success(df):\n",
    "    df_copy=df.copy()\n",
    "    df_copy[\"raiting\"]=np.where(df_copy[\"raiting\"] >= 4.5 ,1,0)\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_to_categorial(df):\n",
    "    df_copy= df.copy()\n",
    "    df_copy = pd.get_dummies(df,columns=['category'],prefix=[\"category\"])\n",
    "    \n",
    "    del df_copy['game_name']\n",
    "    del df_copy['seller']\n",
    "    \n",
    "    \n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_cv(df,XTrain,yTrain):\n",
    "\n",
    "    parameters = {'max_depth':[2,4,6],\"min_samples_split\":[5,10,20,25,50] }\n",
    "    dt = RandomForestClassifier()\n",
    "\n",
    "    clf = GridSearchCV(dt, parameters,scoring=make_scorer(metrics.f1_score, greater_is_better=True))\n",
    "    clf.fit(XTrain, yTrain)\n",
    "\n",
    "    print(\"best parameter set is:\",clf.best_params_,\" and its score was\",clf.best_score_)\n",
    "    \n",
    "    return clf.best_params_,clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_function(X,y):\n",
    "    X_train,X_test,y_train ,y_test = train_test_split(X,y,test_size = 0.3,random_state= 0)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_values(X_train , X_test):\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_train, y_train,X_test,y_test):\n",
    "    forest =  RandomForestClassifier(bootstrap=True, n_estimators=300, random_state=0)\n",
    "\n",
    "    trained_forest = forest.fit(X_train, y_train) \n",
    "\n",
    "    y_pred_train = trained_forest.predict(X_train)\n",
    "    print('f1_score on training data= ', metrics.f1_score(y_true = y_train, y_pred = y_pred_train))\n",
    "\n",
    "    y_pred = trained_forest.predict(X_test)\n",
    "    print('f1_score on test data= ', metrics.f1_score(y_true = y_test, y_pred = y_pred))\n",
    "    return y_pred , trained_forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix_eval(y_test, y_pred):\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Accuracy: \" ,f1_score(average = 'weighted' , y_true= y_test ,y_pred = y_pred))\n",
    "    cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_to_x_and_y(df):\n",
    "    df_copy=df.copy()\n",
    "    y=df_copy[\"raiting\"]\n",
    "    del df_copy[\"raiting\"]\n",
    "    X= df_copy\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score on training data=  1.0\n",
      "f1_score on test data=  0.7857142857142857\n",
      "best parameter set is: {'max_depth': 6, 'min_samples_split': 20}  and its score was 0.7957302645024992\n",
      "Accuracy after improvments =  0.7907995618838992\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.50      0.56       241\n",
      "           1       0.75      0.84      0.79       432\n",
      "\n",
      "    accuracy                           0.72       673\n",
      "   macro avg       0.69      0.67      0.67       673\n",
      "weighted avg       0.71      0.72      0.71       673\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[121, 120],\n",
       "       [ 71, 361]], dtype=int64)"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name = \"C:/Users/tomer/Desktop/תואר ראשון/שנה ב/file_games_EDA.csv\"\n",
    "df = load_csv(file_name)\n",
    "del df[\"Unnamed: 0\"] \n",
    "df = binary_raiting_base_on_success(df) #1 for 4.5 rating and above, 0 for 4.4 and under\n",
    "\n",
    "df_numeric = transfer_to_categorial(df) #transfering string to categorical\n",
    "\n",
    "\n",
    "X,y = split_to_x_and_y(df_numeric) #creating X matrix and y column\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split_function(X,y) #spliting to x train test and y train test\n",
    "\n",
    "X_train , X_test = normalize_values(X_train , X_test) #normalizing values between 0 to 1\n",
    "\n",
    "y_pred, model = train_model(X_train, y_train,X_test,y_test) #first model training\n",
    "\n",
    "\n",
    "best_param, best_score = grid_search_cv(df_numeric\n",
    ",X_train,y_train) #finding the best scores of the last model\n",
    "best_model = RandomForestClassifier(bootstrap=True, random_state = 0 , n_estimators=300, max_depth = best_param.get(\"max_depth\") , min_samples_split = best_param.get(\"min_samples_split\") )\n",
    "#training the model due to the best params from the last model we trained\n",
    "best_model.fit(X_train , y_train)\n",
    "#training the model again\n",
    "y_pred = best_model.predict(X_test)\n",
    "#predicting y according the our best model\n",
    "\n",
    "print('Accuracy after improvments = ', metrics.f1_score(y_true = y_test, y_pred = y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "metrics.confusion_matrix(y_test , y_pred) \n",
    "#the values on the diagonal are values that are correct,\n",
    "# and other diagonal is the one the model failed to predict\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9578cb9989fdc0e033240516ca6fb1d9fde6b079c09585c7ce7292174869855e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
